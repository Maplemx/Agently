import Agently
import subprocess

"""
æ ¹æ®ç”¨æˆ·è¾“å…¥çš„è¦æ±‚ç”Ÿæˆä»£ç ï¼Œåœ¨æœ¬åœ°é€šè¿‡subprocessè°ƒç”¨pythonæ‰§è¡Œä»£ç æ‰§è¡Œç”Ÿæˆä»£ç ï¼Œå¦‚è¿è¡Œå‘ç”Ÿé”™è¯¯ï¼Œåé¦ˆé”™è¯¯ï¼Œç”¨æˆ·è¡¥å……ä¿¡æ¯å’Œå‰ä¸€è½®ç”Ÿæˆçš„ä»£ç ç»™llmï¼Œé‡æ–°ç”Ÿæˆä»£ç ã€‚
"""
agent = (
    Agently.create_agent()
    .set_settings("current_model", "OpenAI") \
    .set_settings("model.OpenAI.auth", {"api_key": "å¡«å…¥ä½ çš„api-key"}) \
    .set_settings("model.OpenAI.options", {"model": "gpt-4o-all"}) \
    )
workflow = Agently.Workflow()


@workflow.chunk()
def generate_code(inputs, storage):
    if storage.get("question") is not None:
        question = storage.get("question")
    else:
        question = input("[User]: ")
    storage.set("question", question)
    additional_context = storage.get("additional_context", "")

    history_code = storage.get("history_code", "")
    if history_code != "":
        history_code = history_code["code"]
    prompt = f"{question}\næ­¤å‰ä»£ç :\n{history_code}\n{additional_context}"
    print(prompt)
    code = (
        agent
        .general("è¾“å‡ºè§„å®š", "è¾“å‡ºå¯ä»¥è¿è¡Œçš„pythonä»£ç ,ä¸è¦åŒ…å«ä»»ä½•è§£é‡Šè¯´æ˜ï¼Œä¸è¦åŒ…å«markdownè¯­æ³•")
        .info("pythonä»£ç è¦æ±‚", "å¿…é¡»æœ‰printè¯­å¥æ˜¾ç¤ºè¿è¡Œç»“æœ")
        .set_role("å·¥ä½œè§„åˆ™ï¼Œ"
                  "1ï¼šå¦‚æœç”¨æˆ·è¾“å…¥ä¸­åŒ…å«ç¬¬ä¸‰æ–¹packageï¼Œå¿…é¡»å…ˆæœç´¢packageçš„ä½¿ç”¨è¯´æ˜ï¼Œä½¿ç”¨æ­£ç¡®çš„ï¼Œæœªè¿‡æ—¶çš„å‡½æ•°åç§°å’Œå‚æ•°åç§°ã€‚"
                  "2ï¼šå¦‚æœè¿”å›çš„additional_contextä¸­åŒ…å«é”™è¯¯ä¿¡æ¯ï¼Œæ ¹æ®é”™è¯¯ä¿¡æ¯ï¼Œä¿®æ”¹ä»£ç ã€‚")
        .input(prompt)
        .output({"code": ("str", "return python code")})
        .start()
    )
    storage.set("generated_code", code)
    storage.set("history_code", code)
    print("[Generated Code]:", code)
    return code


@workflow.chunk()
def execute_code(inputs, storage):
    code = storage.get("generated_code")["code"]
    print(type(code))
    print(code)
    try:
        result = subprocess.check_output(["python", "-c", code], stderr=subprocess.STDOUT, text=True, encoding='utf-8')
        print(result)
        storage.set("execution_result", result)
        return {"success": True}
    except subprocess.CalledProcessError as e:
        storage.set("execution_error", e.output)
        print("[Execution Error]:", e.output)
        return {"success": False}


@workflow.chunk()
def check_execution(inputs, storage):
    print("inputs:", inputs)
    if inputs["default"]["success"]:
        result = storage.get("execution_result")
        print("[Execution Result]:", result)
    else:
        error = storage.get("execution_error")
        print("[Execution Error]:", error)

    user_feedback = input("Is the program result correct? (Y/N): ")
    if user_feedback.upper() == "Y":
        return "success"
    else:
        if not inputs["default"]["success"]:
            storage.set("additional_context", storage.get("execution_error", "") + user_feedback.upper())
        else:
            storage.set("additional_context", user_feedback.upper())
        return "error"


@workflow.chunk()
def goodbye(inputs, storage):
    # ä¿å­˜ä»£ç ï¼ŒæŠŠä»£ç å†™å…¥æ–‡ä»¶
    with open("generated_code.py", "w") as f:
        f.write(storage.get("generated_code")["code"])
    print("Bye~ğŸ‘‹")
    return


workflow.connect_to("generate_code")
(
    workflow.chunks["generate_code"]
    .connect_to("execute_code")
)
workflow.chunks["execute_code"].connect_to("check_execution")

workflow.chunks["check_execution"].if_condition(lambda return_value, storage: return_value == "success").connect_to(
    "goodbye").connect_to("end").else_condition().connect_to("generate_code")

workflow.start()

# eg è¯»å–æœ¬åœ°å›¾ç‰‡file_path="face.png",ä½¿ç”¨çº¢è‰²æ–¹æ¡†æ ‡è®°æ‰€æœ‰äººè„¸ï¼Œå¹¶åœ¨å›¾ç‰‡å·¦ä¸Šè§’æ‰“å°æ¯ä¸ªæ–¹æ¡†ä¸­å¿ƒç‚¹çš„åæ ‡[(x,y),(x,y)]
# User intervention åæ ‡ç‚¹ä¸è¦æ‰“å°åœ¨æ–¹æ¡†çš„ä¸Šæ–¹ï¼Œè€Œæ˜¯ç”¨åˆ—è¡¨çš„æ–¹å¼æ‰“å°åœ¨å›¾ç‰‡çš„å·¦ä¸Šè§’ï¼Œæ–¹æ¡†çš„ä¸­å¿ƒç‚¹ç”¨ç»¿è‰²æ ‡è®°å‡ºæ¥ã€‚
