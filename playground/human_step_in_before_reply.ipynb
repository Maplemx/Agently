{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Maplemx/Agently/blob/main/playground/human_step_in_before_reply.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Human Step In Before Reply"
      ],
      "metadata": {
        "id": "dAzfqHDCAXZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Demo Description\n",
        "\n",
        "**Author:** Agently Team\n",
        "\n",
        "**Prompt Language:** English\n",
        "\n",
        "**Agent Components:** EventListener, ReplyReformer\n",
        "\n",
        "**Description:**\n",
        "\n",
        "Sometimes we don't want the AI agent's response to be the final one directly to user. Instead, we want to have the opportunity to review the response and confirm it before it is sent to user. Or even, sometimes we hope to modify the reply.\n",
        "\n",
        "The following case demonstrates how to do that using Agently framework easily. We can pause the agent's output, undergo human review and verification, modify the reply if it is necessary. Then we can append the new reply into the chat history list.\n",
        "\n",
        "Through this case, we also can observe how AI agent dynamically adjusts its behavior based on the modified reply.\n",
        "\n",
        "This is just a simple example. You can extend upon this by, for examples, using rule system instead of human verification, using this method to build your chatting samples in real time interaction with language model for model fine-tuning or just storing the samples into RoleManager (Read [Agently Application Development Handbook: RoleManager](https://github.com/Maplemx/Agently/blob/main/docs/guidebook/application_development_handbook.ipynb) to explore more).\n",
        "\n",
        "åœ¨ä¸€äº›åœºæ™¯ä¸‹ï¼Œæˆ‘ä»¬å¹¶ä¸å¸Œæœ›AI Agentçš„å›å¤å°±æ˜¯æœ€ç»ˆå›å¤ï¼Œè€Œæ˜¯å¸Œæœ›æˆ‘ä»¬æœ‰æœºä¼šåœ¨AI Agentç»™å‡ºå›å¤å‰è¿›è¡Œå®¡æŸ¥ç¡®è®¤ï¼Œç”šè‡³æ˜¯ä»‹å…¥ä¿®æ”¹å›å¤ã€‚\n",
        "\n",
        "ä¸‹é¢çš„æ¡ˆä¾‹ç»™å‡ºäº†å¦‚ä½•ä½¿ç”¨Agentlyå®Œæˆè¿™ä¸ªè¿‡ç¨‹ã€‚æ¡ˆä¾‹å±•ç°äº†å¦‚ä½•æš‚åœAgentè¾“å‡ºï¼Œäººå·¥å®¡æ ¸ç¡®è®¤æˆ–æ˜¯ä¿®è®¢åå†è¿›è¡Œè¿”å›ï¼Œå¹¶å°†è¿”å›ç»“æœå†™å…¥å¯¹è¯è®°å½•çš„å…¨è¿‡ç¨‹ã€‚\n",
        "\n",
        "é€šè¿‡è¿™ä¸ªæ¡ˆä¾‹ï¼Œæˆ‘ä»¬ä¹Ÿçœ‹åˆ°AI Agentåœ¨è¿‡ç¨‹ä¸­æ ¹æ®ä¿®è®¢ç»“æœï¼Œå³æ—¶è°ƒæ•´äº†è‡ªå·±çš„è¡Œä¸ºåé¦ˆã€‚\n",
        "\n",
        "è¿™åªæ˜¯ä¸€ä¸ªç®€å•çš„æ¡ˆä¾‹ï¼Œä½ å¯ä»¥åŸºäºè¿™ä¸ªæ¡ˆä¾‹åšè¿›ä¸€æ­¥çš„æ‰©å±•ï¼Œä¾‹å¦‚ï¼šä½¿ç”¨å…¶ä»–è§„åˆ™ç³»ç»Ÿæ›¿ä»£äººå·¥å®¡æ ¸ç¡®è®¤ï¼Œä½¿ç”¨è¿™ç§äº¤äº’æ–¹å¼è®­ç»ƒä½ è‡ªå·±çš„å¯¹è¯æ ·æœ¬é›†ç”¨äºæ¨¡å‹å¾®è°ƒæˆ–æ˜¯å­˜å…¥è§’è‰²åº“ç­‰ã€‚\n",
        "\n",
        "å…³äºè§’è‰²åº“ï¼šæƒ³è¦äº†è§£æ›´å¤šï¼Œå¯ä»¥é˜…è¯»[ğŸ“– Agentlyåº”ç”¨å¼€å‘æ‰‹å†Œï¼šRoleManagerç« èŠ‚](https://github.com/Maplemx/Agently/blob/main/docs/guidebook/application_development_handbook.ipynb)"
      ],
      "metadata": {
        "id": "kyLFmv_l-aIx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 1: Install Packages"
      ],
      "metadata": {
        "id": "nRsfMu4lAJZF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install Agently"
      ],
      "metadata": {
        "id": "nsst7pOAANlr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 2: Demo Code"
      ],
      "metadata": {
        "id": "_-1gryYwASPM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "lLaK-w-E-ZKU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6726a69-b773-41d8-e45b-576baea1dc42"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[USER]: ä½ å¥½\n",
            "[Assistant] want to response:\n",
            "ä½ å¥½ï¼æœ‰ä»€ä¹ˆæˆ‘å¯ä»¥å¸®åŠ©ä½ çš„å—ï¼Ÿ\n",
            "Do you confirm? [Y/N]: n\n",
            "Correct reply: å“¦...\n",
            "[Assistant]:  å“¦...\n",
            "[USER]: æ€ä¹ˆäº†ï¼Ÿå¿ƒæƒ…ä¸å¥½å—ï¼Ÿ\n",
            "[Assistant] want to response:\n",
            "ä¸ï¼Œæˆ‘åªæ˜¯è§‰å¾—ä½ æ²¡æœ‰æä¾›è¶³å¤Ÿçš„ä¿¡æ¯ï¼Œæ‰€ä»¥ä¸çŸ¥é“è¯¥å¦‚ä½•å›ç­”ä½ ã€‚å¦‚æœä½ æœ‰ä»€ä¹ˆé—®é¢˜æˆ–è€…éœ€è¦å¸®åŠ©ï¼Œè¯·éšæ—¶å‘Šè¯‰æˆ‘ã€‚\n",
            "Do you confirm? [Y/N]: n\n",
            "Correct reply: å¯¹ï¼Œæˆ‘æ˜¨å¤©æ™šä¸Šæ²¡æœ‰ç¡å¥½\n",
            "[Assistant]:  å¯¹ï¼Œæˆ‘æ˜¨å¤©æ™šä¸Šæ²¡æœ‰ç¡å¥½\n",
            "[USER]: å•Šï¼Ÿä¸¥é‡å—ï¼Ÿè¦ä¸è¦å»åŒ»é™¢çœ‹çœ‹ï¼Ÿ\n",
            "[Assistant] want to response:\n",
            "ä¸ç”¨è¿™ä¹ˆä¸¥é‡ï¼Œåªæ˜¯ç¡çœ ä¸å¤Ÿå……è¶³è€Œå·²ã€‚å¯èƒ½æ˜¯å·¥ä½œå‹åŠ›æ¯”è¾ƒå¤§å¯¼è‡´çš„ã€‚æˆ‘åªéœ€è¦å¤šä¼‘æ¯ä¸€ä¸‹å°±å¥½äº†ã€‚è°¢è°¢ä½ çš„å…³å¿ƒã€‚\n",
            "Do you confirm? [Y/N]: y\n",
            "[Assistant]:  ä¸ç”¨è¿™ä¹ˆä¸¥é‡ï¼Œåªæ˜¯ç¡çœ ä¸å¤Ÿå……è¶³è€Œå·²ã€‚å¯èƒ½æ˜¯å·¥ä½œå‹åŠ›æ¯”è¾ƒå¤§å¯¼è‡´çš„ã€‚æˆ‘åªéœ€è¦å¤šä¼‘æ¯ä¸€ä¸‹å°±å¥½äº†ã€‚è°¢è°¢ä½ çš„å…³å¿ƒã€‚\n",
            "[USER]: #exit\n",
            "------------\n",
            " [Chat History]: \n",
            " [{'role': 'user', 'content': 'ä½ å¥½'}, {'role': 'assistant', 'content': 'å“¦...'}, {'role': 'user', 'content': 'æ€ä¹ˆäº†ï¼Ÿå¿ƒæƒ…ä¸å¥½å—ï¼Ÿ'}, {'role': 'assistant', 'content': 'å¯¹ï¼Œæˆ‘æ˜¨å¤©æ™šä¸Šæ²¡æœ‰ç¡å¥½'}, {'role': 'user', 'content': 'å•Šï¼Ÿä¸¥é‡å—ï¼Ÿè¦ä¸è¦å»åŒ»é™¢çœ‹çœ‹ï¼Ÿ'}, {'role': 'assistant', 'content': 'ä¸ç”¨è¿™ä¹ˆä¸¥é‡ï¼Œåªæ˜¯ç¡çœ ä¸å¤Ÿå……è¶³è€Œå·²ã€‚å¯èƒ½æ˜¯å·¥ä½œå‹åŠ›æ¯”è¾ƒå¤§å¯¼è‡´çš„ã€‚æˆ‘åªéœ€è¦å¤šä¼‘æ¯ä¸€ä¸‹å°±å¥½äº†ã€‚è°¢è°¢ä½ çš„å…³å¿ƒã€‚'}]\n"
          ]
        }
      ],
      "source": [
        "import Agently\n",
        "\n",
        "agent_factory = Agently.AgentFactory()\n",
        "agent_factory\\\n",
        "    .set_settings(\"model.OpenAI.auth\", { \"api_key\": \"\" })\n",
        "\n",
        "agent = agent_factory.create_agent()\n",
        "# We need to manage chat history manually in this case because\n",
        "# we want to change reply.\n",
        "# Agently Team To-Do:\n",
        "# - We will update Session component to support this use case\n",
        "#   to record chat history with edited reply automatically\n",
        "chat_history = []\n",
        "while True:\n",
        "    # Confirm reply or edit it\n",
        "    def human_confirm(data):\n",
        "        global edited_reply\n",
        "        confirm = \"\"\n",
        "        while confirm not in (\"y\", \"n\"):\n",
        "            confirm = input(\"\\nDo you confirm? [Y/N]: \").lower()\n",
        "        if confirm == \"n\":\n",
        "            while edited_reply == \"\":\n",
        "                edited_reply = input(\"Correct reply: \")\n",
        "    # Use ReplyReformer component to change reply\n",
        "    def change_reply(data):\n",
        "        if edited_reply == \"\":\n",
        "            return data[\"reply\"]\n",
        "        else:\n",
        "            return edited_reply\n",
        "\n",
        "    # Start main process\n",
        "    edited_reply = \"\"\n",
        "    global chat_history\n",
        "    user_input = input(\"[USER]: \")\n",
        "    if user_input == \"#exit\":\n",
        "        break\n",
        "    print(\"[Assistant] want to response:\")\n",
        "    # - on_delta: print response in realtime\n",
        "    # - on_done: pause output process and call `human_confirm()`\n",
        "    # - reform_reply: call `change_reply()` to edit final return\n",
        "    reply = agent\\\n",
        "        .chat_history(chat_history)\\\n",
        "        .input(user_input)\\\n",
        "        .on_delta(lambda data: print(data, end=\"\"))\\\n",
        "        .on_done(human_confirm)\\\n",
        "        .reform_reply(change_reply)\\\n",
        "        .start()\n",
        "    print(\"[Assistant]: \", reply)\n",
        "    chat_history.extend([\n",
        "        { \"role\": \"user\", \"content\": user_input },\n",
        "        { \"role\": \"assistant\", \"content\": reply }\n",
        "    ])\n",
        "print(\"------------\\n\", \"[Chat History]: \\n\", chat_history)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "[**_<font color = \"red\">Agent</font><font color = \"blue\">ly</font>_** Framework - Speed up your AI Agent Native application development](https://github.com/Maplemx/Agently)"
      ],
      "metadata": {
        "id": "IT3pSaO2NgkG"
      }
    }
  ]
}