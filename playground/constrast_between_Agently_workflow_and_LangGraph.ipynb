{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Maplemx/Agently/blob/main/playground/constrast_between_Agently_workflow_and_LangGraph.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The Constrast between Agently Workflow and LangGraph"
      ],
      "metadata": {
        "id": "dAzfqHDCAXZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Author:** Agently Team"
      ],
      "metadata": {
        "id": "kyLFmv_l-aIx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Intro ç®€ä»‹\n",
        "\n",
        "This document is a not-complete-compared introduction between Agently Workflow and LangGraph. We wrote this document due to many community developers wondering the differences between two framework modules. But because of the lack of time, we may have some lack of information or mistakes. If you discover those, please [report issues here](https://github.com/Maplemx/Agently/issues/new) or contact us, we would like to change this document after comfirming the mistakes to make this document objective.\n",
        "\n",
        "æœ¬æ–‡æ¡£æ˜¯Agently Workflowå’ŒLangGraphçš„ä¸å…¨é¢æ¯”è¾ƒæ–‡æ¡£ã€‚å› ä¸ºå¾ˆå¤šç¤¾åŒºå¼€å‘è€…æƒ³è¦äº†è§£è¿™ä¸¤ä¸ªæ¡†æ¶æ¨¡å—ä¹‹é—´çš„å·®å¼‚ï¼Œæˆ‘ä»¬æ’°å†™äº†è¿™ç¯‡æ–‡æ¡£ã€‚ä½†ç”±äºå‡†å¤‡æ—¶é—´ä»¥åŠå¯¹LangGraphæ¡†æ¶äº†è§£çš„æ·±åº¦é™åˆ¶ï¼Œæˆ‘ä»¬ä¹Ÿå¯èƒ½åœ¨å¯¹æ¯”æ—¶æœ‰æ‰€çº°æ¼å’Œé”™è¯¯ã€‚å¦‚æœæ‚¨å‘ç°äº†è¿™äº›é—®é¢˜ï¼Œå¯ä»¥[ç‚¹å‡»è¿™é‡Œå‘æˆ‘ä»¬æäº¤](https://github.com/Maplemx/Agently/issues/new)ï¼Œæˆ–æ˜¯ç”¨å…¶ä»–æ–¹å¼ä¸æˆ‘ä»¬å»å¾—è”ç³»ã€‚æˆ‘ä»¬åœ¨ç¡®è®¤é—®é¢˜åï¼Œä¼šåŠæ—¶ä¿®æ”¹æ–‡æ¡£å†…å®¹ï¼Œæ¥ç¡®ä¿æ–‡æ¡£çš„å®¢è§‚æ€§ã€‚"
      ],
      "metadata": {
        "id": "usZNKT8g4QXa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Compare Table åŠŸèƒ½å¯¹æ¯”è¡¨\n",
        "\n",
        "|Feature|Agently Workflow|LangGraph|\n",
        "|---|---|---|\n",
        "|**Create Workflow Instance**<br /><br />**åˆ›å»ºå·¥ä½œæµå¯¹è±¡**|âœ…<br />Created by `Agently.Workflow()`<br /><br />ç”±`Agently.Workflow()`ç±»åˆ›å»º|âœ…<br />Created by `langgraph.graph.StateGraph()`<br />Customized structure class `State` is required for workflow data communication.<br /><br />é€šè¿‡`langgraph.graph.StateGraph()`ç±»åˆ›å»º<br />éœ€è¦ä¼ å…¥è‡ªå®šä¹‰ç»“æ„ç±»`State`ä½œä¸ºè¡¥å……ï¼Œç”¨äºåç»­å·¥ä½œæµä¸­çš„æ•°æ®ä¼ é€’ç»“æ„|\n",
        "|**Define Workflow Chunk/Node**<br /><br />**å®šä¹‰å·¥ä½œæµå—/èŠ‚ç‚¹**|âœ… ğŸš€<br />Defined by function decorator `@workflow.chunk()`<br />Defined chunks will be found in dict `workflow.chunks`<br />Default named by function name.<br /><br />ç”±è£…é¥°å™¨`@workflow.chunk()`è£…é¥°æ‰§è¡Œå‡½æ•°å®Œæˆå®šä¹‰<br />å®šä¹‰å®Œæˆçš„å·¥ä½œå—å°†å¯ä»¥åœ¨å­—å…¸`workflow.chunks`ä¸­æ‰¾åˆ°<br />å·¥ä½œå—é»˜è®¤å‘½åä¸æ‰§è¡Œå‡½æ•°å‘½åä¸€è‡´|âœ…<br />Define node function directly<br />Register as a node by `workflow.add_node(\"node name\", node_func)`<br /><br />ç›´æ¥å®šä¹‰å‡½æ•°<br />é€šè¿‡`workflow.add_node(\"node name\", node_func)`æ–¹æ³•æ³¨å†Œæˆä¸ºä¸€ä¸ªnodeèŠ‚ç‚¹|\n",
        "|**Executor Function Compatibility**<br />**å·¥ä½œæµå—/èŠ‚ç‚¹è¿è¡Œå‡½æ•°å…¼å®¹æ€§**|ğŸŸ <br />Any Modules<br />Support async `workflow.start_async()`<br />Support streaming handler using listener<br />Not support streaming output using generator<br /><br />æ”¯æŒåœ¨è¿è¡Œå‡½æ•°å†…ä½¿ç”¨ä»»ä½•å…¶ä»–æ¨¡å—<br />æ”¯æŒå¼‚æ­¥`workflow.start_async()`<br />æ”¯æŒä½¿ç”¨ç›‘å¬å™¨å¤„ç†æµå¼è¾“å‡º<br />ä¸æ”¯æŒä½¿ç”¨generatorè¿›è¡Œæµå¼è¾“å‡º|âœ…<br />Any Modules<br />Support async `app.ainvoke()`<br />Support streaming output using generator `app.astream()`<br /><br />æ”¯æŒåœ¨è¿è¡Œå‡½æ•°å†…ä½¿ç”¨ä»»ä½•å…¶ä»–æ¨¡å—<br />æ”¯æŒå¼‚æ­¥ `app.ainvoke()`<br />æ”¯æŒä½¿ç”¨generatorè¿›è¡Œæµå¼è¾“å‡º`workflow.astream()`|\n",
        "|**Start and End Points**<br /><br />**å¼€å§‹å’Œç»“æŸ**|âœ… ğŸš€<br />Provide standard chunk type `Start` and `END`<br />Those two standard chunks will be put into `workflow.chunks` by default when workflow is created<br /><br />æä¾›æ ‡å‡†çš„chunk_typeï¼Œ`Start`å’Œ`End`<br />ä¸¤ä¸ªåä¸º\"start\"å’Œ\"end\"çš„æ ‡å‡†å·¥ä½œå—åœ¨å·¥ä½œæµåˆ›å»ºæ—¶ä¼šé»˜è®¤å†…ç½®åˆ°å·¥ä½œå—æ± ä¸­|âœ…<br />Using `workflow.set_entry_ponit(\"node name\", node_func)` to set the node to start<br />Using `langgraph.graph.END` as the ending node<br /><br />é€šè¿‡`workflow.set_entry_ponit(\"node name\", node_func)`çš„æ–¹å¼ç¡®å®šèµ·ç‚¹å—<br />ä½¿ç”¨å†…ç½®çš„langgraph.graph.ENDä½œä¸ºç»ˆç‚¹å—|\n",
        "|**Normal Connection**<br /><br />**æ™®é€šè¿æ¥**|âœ… ğŸš€<br />Connect two chunks using`workflow.chunks[\"from_chunk_name\"].connect_to(workflow.chunks[\"to_chunk_name\"])`<br />Simplify expression: `.connect_to(\"to_chunk_name\")`<br />Chain expression like `.connect_to(\"chunk_a\").connect_to(\"chunk_b\")` supported.<br /><br />ä½¿ç”¨`workflow.chunks[\"from_chunk_name\"].connect_to(workflow.chunks[\"to_chunk_name\"])`è¿æ¥<br />æ”¯æŒä½¿ç”¨`.connect_to(\"to_chunk_name\")`æ–¹å¼ç®€å†™<br />æ”¯æŒ`.connect_to(\"chunk_a\").connect_to(\"chunk_b\")`è¿™æ ·çš„é“¾å¼è¡¨è¾¾|âœ…<br />Connect two nodes using `workflow.add_edge(\"from_node_name\", \"to_node_name\")`<br /><br />ä½¿ç”¨`workflow.add_edge(\"from_node_name\", \"to_node_name\")`è¿æ¥ä¸¤ä¸ªnodeèŠ‚ç‚¹|\n",
        "|**Conditional Connection**<br /><br />**æ¡ä»¶è¿æ¥**|ğŸŸ <br />Using expression like `.if_condition(lambda value, storage: value==1)` in chain expression<br />Get return value from last chunk as `value` and get workflow storage as `storage`<br />Support `.if_condition()`, `.else_condition()` currently<br />Can not support more than 2 conditions branches right now or use more \"if-else\" combination to express but we're working on it<br /><br />ä½¿ç”¨ç±»ä¼¼`.if_condition(lambda value, storage: value==1)`çš„å½¢å¼è¿›è¡Œæ¡ä»¶åˆ¤æ–­è¡¨è¾¾<br />ä»ä¸Šä¸€ä¸ªè¿æ¥å—è·å–å‡½æ•°returnçš„è¿”å›å€¼ä½œä¸º`value`ï¼Œä½¿ç”¨å·¥ä½œæµå…¨å±€å­˜å‚¨ä½œä¸º`storage`<br />ç›®å‰åªèƒ½æ”¯æŒä¸è¶…è¿‡ä¸¤ç§æƒ…å†µçš„åˆ†æ”¯ï¼Œæˆ–æ˜¯ä½¿ç”¨å¤šä¸ªif-elseç»„åˆæ¥è¿›è¡Œè¡¨è¾¾ï¼Œæˆ‘ä»¬æ­£åœ¨æ”¹è¿›è¿™ä¸€ç‚¹|âœ… ğŸš€<br />Using `workflow.add_conditional_edges(\"from_node_name\", condition_func, { \"return_value_1\": \"to_node_name_1\", ... })` to define conditional edges<br />Support return more than 2 conditions to branch<br /><br />ä½¿ç”¨`workflow.add_conditional_edges(\"from_node_name\", condition_func, { \"return_value_1\": \"to_node_name_1\", ... })`è¿›è¡Œè¡¨è¾¾<br />æ”¯æŒåœ¨ä¸€ä¸ªæ¡ä»¶åˆ¤æ–­å‡½æ•°è¿”å›2ä¸ªä»¥ä¸Šçš„æ¡ä»¶ç»“æœï¼Œå¹¶è¿›è¡Œåˆ†æ”¯è§„åˆ’|\n",
        "|**Ring Connection**<br />**æˆç¯æ”¯æŒ**|âœ…<br />Yes, you can connect chunks into a ring to repeatly processing<br />You can use `if_condition()` to break the ring<br /><br />æ”¯æŒï¼Œä½ å¯ä»¥å°†å¤šä¸ªå·¥ä½œå—é¦–å°¾ç›¸è¿å½¢æˆç¯çŠ¶æ¥å¤šæ¬¡æ‰§è¡Œ<br />ä½ å¯ä»¥ä½¿ç”¨`if_condition()`è¿›è¡Œæ¡ä»¶åˆ¤æ–­æ¥è·³å‡ºç¯|âœ…<br />Yes, you can connect nodes into a ring to repeatly processing<br />You can use `workflow.add_conditional_edges()` to break the ring<br /><br />æ”¯æŒï¼Œä½ å¯ä»¥å°†å¤šä¸ªå·¥ä½œèŠ‚ç‚¹é¦–å°¾ç›¸è¿å½¢æˆç¯çŠ¶æ¥å¤šæ¬¡æ‰§è¡Œ<br />ä½ å¯ä»¥ä½¿ç”¨`workflow.add_conditional_edges()`è¿›è¡Œæ¡ä»¶åˆ¤æ–­æ¥è·³å‡ºç¯|\n",
        "|**Parallel Branch**<br />**å¹¶è¡Œåˆ†æ”¯**|âœ…<br />You can connect one chunk to two or more different chunks and connect all these chunks to different handles of the end chunk to make a parallel branch<br /><br />ä½ å¯ä»¥é€šè¿‡å°†ä¸€ä¸ªå·¥ä½œå—è¿æ¥å¤šä¸ªä¸‹æ¸¸å—ï¼Œå¹¶å°†è¿™äº›ä¸‹æ¸¸å—è¿æ¥åˆ°ç»ˆç‚¹å—çš„ä¸åŒç«¯ç‚¹ä¸Šï¼ˆä¸åŒç«¯ç‚¹æ‰ä¼šç­‰å¾…ä¸Šæ¸¸å…¨éƒ¨ä»»åŠ¡çš„å®Œæˆï¼‰æ¥æ„é€ å¹¶è¡Œåˆ†æ”¯|âŒ<br />Can not support, if you try to connect one node to two or more different nodes you will receive an error<br /><br />ä¸æ”¯æŒï¼Œå¦‚æœä½ å°è¯•å°†ä¸€ä¸ªnodeä¸‹æ¸¸åŒæ—¶è¿æ¥å¤šä¸ªnodeï¼Œä½ ä¼šæ”¶åˆ°ä¸€ä¸ªé”™è¯¯è­¦å‘Š|\n",
        "|**Loop by List**<br />**åŸºäºåˆ—è¡¨çš„å¾ªç¯**|âœ…<br />Using `.loop_with(sub_workflow)` to pass items in list to sub workflow one by one and get a list return result<br /><br />æ”¯æŒä½¿ç”¨`.loop_with(sub_workflow)`å°†ä¸Šæ¸¸å—çš„åˆ—è¡¨ä¸­çš„å…ƒç´ ä¸€ä¸ªä¸€ä¸ªåœ°ä¼ é€’ç»™å­å·¥ä½œæµsub workflowï¼Œå¹¶ä»å­å·¥ä½œæµè·å¾—æ±‡é›†æˆåˆ—è¡¨çš„è¿”å›ç»“æœ|âŒ<br />Not found in quick start guide book.<br /><br />åœ¨å¿«é€Ÿå…¥é—¨çš„ç›¸å…³æ–‡æ¡£ä¸­æœªæ‰¾åˆ°|\n",
        "|**Start Workflow and Initial Data**<br />**å¯åŠ¨å·¥ä½œæµåŠå¯åŠ¨æ—¶æ•°æ®ä¼ é€’**|âœ…<br />Using `result = workflow.start(initial_inputs, storage=initial_storage)` to start workflow and get final result from chunk \"end\"'s return<br />Passing `initial_inputs` to parameter `inputs` of next chunk's executor function<br />Setting `initial_storage` to workflow's global storage<br /><br />ä½¿ç”¨`result = workflow.start(initial_inputs, storage=initial_storage)`çš„æ–¹å¼å¯åŠ¨å·¥ä½œæµ<br />å°†`initial_inputs`é€šè¿‡å·¥ä½œå—æ‰§è¡Œå‡½æ•°çš„`inputs`å‚æ•°ä¼ ç»™ç¬¬ä¸€ä¸ªå¤„ç†å·¥ä½œå—<br />å°†`initial_storage`ä½œä¸ºå·¥ä½œæµå…¨å±€æ•°æ®`storage`çš„åˆå§‹æ•°æ®|âœ…<br />Using `app = workflow.compile()` to compile workflow first<br />Using `final_state = app.invoke({\"state_key\": state_value}, config={})` to start workflow and get final state as result after workflow processing<br />Passing initial state data in `app.invoke()` to set initial state<br /><br />éœ€è¦ä½¿ç”¨`app = workflow.compile()`å°†å·¥ä½œæµäº‹å…ˆè¿›è¡Œç¼–è¯‘<br />é€šè¿‡`final_state = app.invoke({\"state_key\": state_value}, config={})`å¯åŠ¨å·¥ä½œæµï¼Œå¹¶å°†è¿è¡Œåçš„æœ€ç»ˆstateæ•°æ®è¿”å›<br />åœ¨`app.invoke()`æ–¹æ³•ä¸­ä¼ é€’åˆå§‹çš„stateæ•°æ®|\n",
        "|**Runtime Data Communication**<br />**è¿è¡Œæ—¶æ•°æ®é€šè®¯**|âœ…<br />Using `inputs` to passing data from last chunk to next chunk<br />Using different handles of chunk to manage data passing and running orders<br />Using `stroage` to store workflow global data<br /><br />ä½¿ç”¨`inputs`åœ¨å…·æœ‰ç›´æ¥è¿æ¥é¡ºåºå…³ç³»çš„å·¥ä½œå—ä¹‹é—´è¿›è¡Œæ•°æ®ä¼ é€’<br />ï¼ˆæä¾›å¼ºæ—¶åºç›¸å…³çš„æ•°æ®çš„å¯é ä¼ é€’æ–¹å¼ï¼‰<br />åœ¨ä¸€ä¸ªå·¥ä½œå—ä¸Šä½¿ç”¨å¤šä¸ªç«¯ç‚¹ï¼ˆhandlesï¼‰è¿›è¡Œæ•°æ®ä¼ é€’åˆ†ç»„åŠæ‰§è¡Œé¡ºåºæ§åˆ¶<br />ï¼ˆå¦‚å…·æœ‰ä¸¤ä¸ªè¾“å…¥ç«¯ç‚¹çš„å·¥ä½œå—ä¼šç­‰å¾…ä¸¤ä¸ªç«¯ç‚¹å¯¹åº”çš„å‰ç½®åˆ†æ”¯æµå®Œæˆå¤„ç†åæ‰å¼€å§‹å·¥ä½œï¼‰<br />ä½¿ç”¨`storage`è¿›è¡Œå·¥ä½œæµå…¨å±€æ•°æ®ä¼ é€’|ğŸŸ <br />Using pre-stated `state` only and you can not customize `state`'s structure in workflow<br />åªä½¿ç”¨é¢„å…ˆå®šä¹‰å¥½ç»“æ„çš„`state`è¿›è¡Œå·¥ä½œè¿‡ç¨‹æ•°æ®ä¼ é€’ï¼Œå¹¶ä¸”å·¥ä½œæµå¤„ç†è¿‡ç¨‹ä¸­ä¸èƒ½ä¿®æ”¹`state`çš„ç»“æ„ã€‚<br />ï¼ˆæ— æ³•åº”å¯¹å¤æ‚å¤„ç†è¿‡ç¨‹æˆ–æ˜¯å¤šåˆ†æ”¯æ—¶åºä¾èµ–è¾ƒé«˜çš„åœºæ™¯ï¼Œå› ä¸ºè¿™æ—¶`state`é”®å€¼çš„çŠ¶æ€ä¸ç¡®å®šæ€§å˜é«˜ï¼‰<br />ï¼ˆè¿™å¯èƒ½ä¹Ÿæ˜¯LangGraphæ²¡æœ‰æ”¯æŒå¹¶è¡Œåˆ†æ”¯çš„åŸå› ï¼‰|\n",
        "|**Saving Data and Restore**<br /><br />**å·¥ä½œæ•°æ®ä¿å­˜å’Œæ¢å¤**|âœ…<br />Using `workflow.storage.get_all()` to get storage data and using `workflow.storage.set_with_dict()` to reset storage data<br /><br />æ”¯æŒä½¿ç”¨`workflow.storage.get_all()`å–å‡ºå·¥ä½œæµçš„å…¨å±€æ•°æ®ï¼Œå¹¶ç”¨`workflow.storage.set_with_dict()`æ›´æ–°å·¥ä½œæµå…¨å±€æ•°æ®|âœ… ğŸš€<br />Using `checkpointer = langgraph.checkpoint.MemorySaver()` to persist state between graph runs<br /><br />ä½¿ç”¨`checkpointer = langgraph.checkpoint.MemorySaver()`åœ¨å¤šæ¬¡å·¥ä½œæµè¿è¡Œé—´ä¿å­˜çŠ¶æ€æ•°æ®|\n",
        "|**Workflow Graph**<br />**å·¥ä½œæµå›¾å½¢ç”Ÿæˆ**|âœ…<br />Using `workflow.draw()` to get mermaid code<br /><br />æ”¯æŒé€šè¿‡`workflow.draw()`è·å–å·¥ä½œæµçš„Mermaidä»£ç |âœ… ğŸš€<br />Compile workflow by `app = workflow.compile()` first then use `app.get_graph().draw_mermaid()` to get mermaid code<br />Support ASCII, Mermaid, PNG<br /><br />é€šè¿‡`app = workflow.compile()`å¯¹å·¥ä½œæµè¿›è¡Œç¼–è¯‘åï¼Œå¯ä»¥é€šè¿‡`app.get_graph().draw_mermaid()`çš„æ–¹å¼ç”Ÿæˆå›¾å½¢ä»£ç <br />é™¤äº†Mermaidå¤–ï¼Œè¿˜æ”¯æŒASCIIå’ŒPNGæ ¼å¼è¾“å‡º|\n",
        "|**Framework Ecosystem**<br />**æ¡†æ¶ç”Ÿæ€**|âœ…<br />Agently Settings to switch between models speedily without changing any logic code<br />Agently Agent Request to make model request easily with solid format control<br />Agently P-YAML to seperate coding logic and model requesting prompt<br />English and Chinese language support<br /><br />Agently Settingså¸®åŠ©å¼€å‘è€…ä¸ä¿®æ”¹ä»»ä½•ä¸šåŠ¡é€»è¾‘ä»£ç ï¼Œä½¿ç”¨ç®€å•é…ç½®å°±èƒ½åˆ‡æ¢é©±åŠ¨æ¨¡å‹<br />Agently Agent Requestå¸®åŠ©å¼€å‘è€…ç›´è§‚è½»æ¾åœ°å¯¹æ¨¡å‹è¯·æ±‚è¿›è¡Œè¡¨è¾¾ï¼Œå¹¶è·å¾—é«˜ç¨³å®šæ€§çš„ç»“æ„åŒ–æ•°æ®è¾“å‡º<br />Agently P-YAMLå¸®åŠ©å¼€å‘è€…å°†æ¨¡å‹è¯·æ±‚æç¤ºä¼˜åŒ–ç­‰å·¥ä½œä»ä¸šåŠ¡ä»£ç ä¸­åˆ†ç¦»å‡ºæ¥<br />æä¾›è‹±æ–‡åŠä¸­æ–‡åŒè¯­æ”¯æŒ|âœ…<br />World famous LangChain framework<br />LangSmith and LangServer to help developers monitor and deploy application<br />English support only<br /><br />LangChainæ˜¯ä¸–ç•ŒçŸ¥åæ¡†æ¶<br />LangSmithå’ŒLangServerèƒ½å¸®åŠ©å¼€å‘è€…è¿›è¡Œåº”ç”¨è¿è¡Œè¿‡ç¨‹ç›‘æ§å’ŒæœåŠ¡éƒ¨ç½²<br />åªæä¾›è‹±æ–‡æ”¯æŒ|\n",
        "\n",
        "å›¾ä¾‹è¯´æ˜ï¼š\n",
        "âœ… å®Œå…¨æ”¯æŒæ­¤èƒ½åŠ›\n",
        "âŒ ä¸æ”¯æŒæ­¤èƒ½åŠ›æˆ–è¾ƒä¸ºå¤æ‚\n",
        "ğŸŸ  éƒ¨åˆ†æ”¯æŒæ­¤èƒ½åŠ›ï¼Œæˆ–åœ¨æ”¯æŒæ­¤èƒ½åŠ›æ—¶æœ‰ç‘•ç–µï¼Œéœ€è¦æ”¹è¿›\n",
        "ğŸš€ åœ¨æ”¯æŒæ­¤èƒ½åŠ›æ—¶ï¼Œæä¾›äº†ä¾¿åˆ©æ˜“ç”¨çš„æ–¹æ³•"
      ],
      "metadata": {
        "id": "fSd4S4hW7Wlk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Code Compatation å®ç°ä»£ç å¯¹æ¯”"
      ],
      "metadata": {
        "id": "lezyByPlLiDE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Subject Settings å‘½é¢˜è®¾è®¡\n",
        "\n",
        "We'll try to cover as many abilities from the table above as possible to present differences between two frameworks.\n",
        "\n",
        "ä¸ºäº†æ›´å¥½å±•ç°ä¸åŒæ¡†æ¶çš„ç‰¹ç‚¹ï¼Œæˆ‘ä»¬è®¾è®¡çš„å‘½é¢˜å°†å°½å¯èƒ½å¤šåœ°è¦†ç›–ä¸Šè¡¨ä¸­çš„ç›¸å…³èƒ½åŠ›ã€‚"
      ],
      "metadata": {
        "id": "gnhYCwYilROU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img width=\"1024\" src=\"https://github.com/Maplemx/Agently/assets/4413155/392bb081-99c5-44ba-ab64-c752dc8443ae\" />"
      ],
      "metadata": {
        "id": "KAhu4YX7zQ_e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Task Description**\n",
        "\n",
        "1. Pass data `times=0` into workflow when workflow start\n",
        "2. Ask user to input some string\n",
        "3. Start two parallel branches:\n",
        "\n",
        "    - Branch A:\n",
        "        1. Add `times` by 1\n",
        "    \n",
        "    - Branch B:\n",
        "        1. Split user input string character by character into a list\n",
        "        2. Loop the character item in the list and print character item one by one (In real task this sub workflow should be much more complex)\n",
        "        3. Collect character items from sub workflow and regroup them into a string, print it and append it into list `all_user_inputs`.\n",
        "\n",
        "4. When two branches all finish their works, make a judgement about value of `times`, if `times>=3` then end this workflow, else go back to step 2.\n",
        "5. Get `all_user_inputs` after workflow finish and print it.\n",
        "\n",
        "**ä»»åŠ¡æè¿°**\n",
        "\n",
        "1. å°†æ•°æ®`times=0`åœ¨å·¥ä½œæµå¼€å§‹å·¥ä½œæ—¶ï¼Œä¼ é€’åˆ°å·¥ä½œæµå†…éƒ¨\n",
        "2. è¯·ç”¨æˆ·è¾“å…¥ä¸€ä¸ªè‹¥å¹²å­—ç¬¦é•¿åº¦çš„å­—ç¬¦ä¸²\n",
        "3. å¼€å¯ä¸¤ä¸ªå¹³è¡Œåˆ†æ”¯ï¼š\n",
        "\n",
        "    - åˆ†æ”¯Aï¼š\n",
        "        1. å°†`times`çš„å€¼å¢åŠ 1\n",
        "\n",
        "    - åˆ†æ”¯Bï¼š\n",
        "        1. å°†ç”¨æˆ·è¾“å…¥çš„å­—ç¬¦ä¸²æ‹†åˆ†æˆç”±å•ä¸ªå­—ç¬¦ç»„æˆçš„list\n",
        "        2. å¾ªç¯è®¿é—®listä¸­çš„æ¯ä¸€ä¸ªå…ƒç´ ï¼Œè¿›è¡Œç›¸åŒçš„å¤„ç†è¿‡ç¨‹ï¼šæ‰“å°å½“å‰å…ƒç´ ä¿¡æ¯ï¼ˆåœ¨çœŸå®çš„ä»»åŠ¡ä¸­ï¼Œè¿™ä¸ªå­å·¥ä½œæµçš„ä»»åŠ¡å¤æ‚åº¦å…¶å®ä¼šé«˜å¾ˆå¤šï¼‰\n",
        "        3. å›æ”¶å­å·¥ä½œæµä¸­çš„å­—ç¬¦å…ƒç´ å¹¶å°†å®ƒä»¬é‡ç»„ä¸ºä¸€ä¸ªå­—ç¬¦ä¸²ï¼Œç„¶åæŠŠå­—ç¬¦ä¸²æ‰“å°å‡ºæ¥ï¼Œå¹¶æŠŠå­—ç¬¦ä¸²æ”¾å…¥list`all_user_inputs`ä¸­å­˜å‚¨\n",
        "\n",
        "4. å½“åˆ†æ”¯Aå’ŒBéƒ½å®Œæˆåï¼Œåšä¸€ä¸ªå…³äº`times`å½“å‰å€¼çš„åˆ¤æ–­ï¼Œå¦‚æœ`times>=3`é‚£ä¹ˆå·¥ä½œæµç»“æŸï¼Œå¦åˆ™å›åˆ°æ­¥éª¤2\n",
        "5. åœ¨å·¥ä½œæµæ‰§è¡Œå®Œæ¯•åï¼Œè·å–`all_user_inputs`çš„ç»“æœå¹¶æ‰“å°å‡ºæ¥"
      ],
      "metadata": {
        "id": "htuI0uD1zerh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Install Packages"
      ],
      "metadata": {
        "id": "lSW2Nbsl-WWJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q -U langgraph Agently mermaid-python"
      ],
      "metadata": {
        "id": "qVq52vPy-Vu7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### LangGraph"
      ],
      "metadata": {
        "id": "YLb3gQAILqBa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langgraph.graph import StateGraph, END\n",
        "\n",
        "# Define State Class\n",
        "from typing import TypedDict, Optional\n",
        "\n",
        "## I have to go back here to modified this class\n",
        "## when I write node functions down below time to time\n",
        "## because I find out that I need to pass more other data in process\n",
        "class State(TypedDict):\n",
        "    times: Optional[int] = None\n",
        "    user_input_data: Optional[str] = None\n",
        "    splited_list: Optional[list] = None\n",
        "    all_user_inputs: Optional[list] = None\n",
        "\n",
        "# Create Workflow Instance\n",
        "workflow = StateGraph(State)\n",
        "\n",
        "# Define Node Functions\n",
        "def start(state):\n",
        "    return\n",
        "\n",
        "def user_input(state):\n",
        "    return { \"user_input_data\": input(\"[Input String]: \") }\n",
        "\n",
        "def add_times(state):\n",
        "    return { \"times\": state.get(\"times\") + 1 }\n",
        "\n",
        "def split_input_to_list(state):\n",
        "    user_input_data = state.get(\"user_input_data\")\n",
        "    splited_list = []\n",
        "    for char in user_input_data:\n",
        "        splited_list.append(char)\n",
        "    return { \"splited_list\": splited_list }\n",
        "\n",
        "## I can't use a loop using LangGraph here so I just combine\n",
        "## `loop`, `print_char` item by item, `regroup_input` 3 steps\n",
        "## into this one\n",
        "def combined_steps(state):\n",
        "    splited_list = state.get(\"splited_list\")\n",
        "    regrouped_input = \"\"\n",
        "    for char in splited_list:\n",
        "        print(char)\n",
        "        regrouped_input += char\n",
        "    print(regrouped_input)\n",
        "    all_user_inputs = state.get(\"all_user_inputs\") or []\n",
        "    all_user_inputs.append(regrouped_input)\n",
        "    return { \"all_user_inputs\": all_user_inputs }\n",
        "\n",
        "# Register Node\n",
        "workflow.add_node(\"start\", start)\n",
        "workflow.add_node(\"user_input\", user_input)\n",
        "workflow.add_node(\"split_input_to_list\", split_input_to_list)\n",
        "workflow.add_node(\"combined_steps\", combined_steps)\n",
        "workflow.add_node(\"add_times\", add_times)\n",
        "\n",
        "# Connection\n",
        "workflow.set_entry_point(\"start\")\n",
        "workflow.add_edge(\"start\", \"user_input\")\n",
        "workflow.add_edge(\"user_input\", \"split_input_to_list\")\n",
        "## the connections seem simple because I warpped\n",
        "## the loop sub workflow logic into `combined_steps`\n",
        "workflow.add_edge(\"split_input_to_list\", \"combined_steps\")\n",
        "## I can not build parallel branches so I just make them run in orders\n",
        "## In this case that doesn't matter but maybe not in other cases\n",
        "workflow.add_edge(\"combined_steps\", \"add_times\")\n",
        "workflow.add_conditional_edges(\n",
        "  \"add_times\",\n",
        "  lambda state: \"end\" if state.get(\"times\") >= 3 else \"continue\",\n",
        "  {\n",
        "    \"end\": END,\n",
        "    \"continue\": \"user_input\"\n",
        "  }\n",
        ")\n",
        "\n",
        "# Compile\n",
        "app = workflow.compile()"
      ],
      "metadata": {
        "id": "vkf9oNI54Zuv"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Draw Mermaid Workflow Graph\n",
        "from mermaid import Mermaid\n",
        "Mermaid(app.get_graph().draw_mermaid())"
      ],
      "metadata": {
        "id": "HuUy6ZpO-2ZS",
        "outputId": "1f2b89e8-82d4-45ea-91fd-c79f037d8442",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 621
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<mermaid.mermaid.Mermaid at 0x7e37d1265780>"
            ],
            "text/html": [
              "\n",
              "        <div class=\"mermaid-4a66a537-137e-4af1-aaf4-c6c6400e58bd\"></div>\n",
              "        <script type=\"module\">\n",
              "            import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@10.1.0/+esm'\n",
              "            const graphDefinition = '%%{init: {\"flowchart\": {\"curve\": \"linear\"}}}%%\\ngraph TD;\\n\t__start__[__start__]:::startclass;\\n\t__end__[__end__]:::endclass;\\n\tstart([start]):::otherclass;\\n\tuser_input([user_input]):::otherclass;\\n\tsplit_input_to_list([split_input_to_list]):::otherclass;\\n\tcombined_steps([combined_steps]):::otherclass;\\n\tadd_times([add_times]):::otherclass;\\n\t__start__ --> start;\\n\tcombined_steps --> add_times;\\n\tsplit_input_to_list --> combined_steps;\\n\tstart --> user_input;\\n\tuser_input --> split_input_to_list;\\n\tadd_times -. end .-> __end__;\\n\tadd_times -. continue .-> user_input;\\n\tclassDef startclass fill:#ffdfba;\\n\tclassDef endclass fill:#baffc9;\\n\tclassDef otherclass fill:#fad7de;\\n';\n",
              "            const element = document.querySelector('.mermaid-4a66a537-137e-4af1-aaf4-c6c6400e58bd');\n",
              "            const { svg } = await mermaid.render('graphDiv-4a66a537-137e-4af1-aaf4-c6c6400e58bd', graphDefinition);\n",
              "            element.innerHTML = svg;\n",
              "        </script>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Start Workflow and Get Result\n",
        "result = app.invoke({ \"times\": 0 })\n",
        "print(result[\"all_user_inputs\"])"
      ],
      "metadata": {
        "id": "YVAwWYRT_XiE",
        "outputId": "0a9538eb-53ad-459c-9160-6e5dddd88323",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Input String]: LangGraph\n",
            "L\n",
            "a\n",
            "n\n",
            "g\n",
            "G\n",
            "r\n",
            "a\n",
            "p\n",
            "h\n",
            "LangGraph\n",
            "[Input String]: and\n",
            "a\n",
            "n\n",
            "d\n",
            "and\n",
            "[Input String]: Agently\n",
            "A\n",
            "g\n",
            "e\n",
            "n\n",
            "t\n",
            "l\n",
            "y\n",
            "Agently\n",
            "['LangGraph', 'and', 'Agently']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Agently Workflow"
      ],
      "metadata": {
        "id": "JmBbXla7L5nQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import Agently\n",
        "\n",
        "# Create Workflow Instance\n",
        "workflow = Agently.Workflow()\n",
        "sub_workflow = Agently.Workflow()\n",
        "\n",
        "# Define Chunks\n",
        "## (Including define chunk function and register chunk)\n",
        "@workflow.chunk()\n",
        "def user_input(inputs, storage):\n",
        "    return input(\"[Input String]: \")\n",
        "\n",
        "@workflow.chunk()\n",
        "def add_times(inputs, storage):\n",
        "    storage.set(\"times\", storage.get(\"times\") + 1)\n",
        "    return\n",
        "\n",
        "## Need a wait point chunk to wait two branches to finish\n",
        "@workflow.chunk()\n",
        "def wait_point(inputs, storage):\n",
        "    return\n",
        "\n",
        "@workflow.chunk()\n",
        "def split_input_to_list(inputs, storage):\n",
        "    user_input_data = inputs[\"default\"]\n",
        "    splited_list = []\n",
        "    for char in user_input_data:\n",
        "        splited_list.append(char)\n",
        "    return splited_list\n",
        "\n",
        "## Use sub_workflow to handle items from `split_input_to_list`\n",
        "@sub_workflow.chunk()\n",
        "def print_char(inputs, storage):\n",
        "    print(inputs[\"default\"])\n",
        "    return inputs[\"default\"]\n",
        "\n",
        "@workflow.chunk()\n",
        "def regroup_input(inputs, storage):\n",
        "    regrouped_input = \"\"\n",
        "    for item in inputs[\"default\"]:\n",
        "        regrouped_input += item[\"default\"]\n",
        "    print(regrouped_input)\n",
        "    return regrouped_input\n",
        "\n",
        "@workflow.chunk()\n",
        "def append_to_all_user_inputs(inputs, storage):\n",
        "    all_user_inputs = storage.get(\"all_user_inputs\", [])\n",
        "    all_user_inputs.append(inputs[\"default\"])\n",
        "    storage.set(\"all_user_inputs\", all_user_inputs)\n",
        "    return\n",
        "\n",
        "# Connection\n",
        "## Sub Workflow in Loop\n",
        "sub_workflow.connect_to(\"print_char\").connect_to(\"end\")\n",
        "\n",
        "## Branch A\n",
        "(\n",
        "    workflow\n",
        "        .connect_to(\"user_input\")\n",
        "        .connect_to(\"add_times\")\n",
        "        ## Use different handle to wait different branch\n",
        "        .connect_to(\"wait_point.branch_a\")\n",
        "        .if_condition(lambda value, storage: storage.get(\"times\") >= 3)\n",
        "            .connect_to(\"end\")\n",
        "        .else_condition()\n",
        "            .connect_to(\"user_input\")\n",
        ")\n",
        "\n",
        "## Branch B\n",
        "(\n",
        "    ## Only define connections those were not defined yet\n",
        "    ## So, start from `user_input`\n",
        "    workflow.chunks[\"user_input\"]\n",
        "        .connect_to(\"split_input_to_list\")\n",
        "        ## Use .loop_with() to call sub workflow\n",
        "        .loop_with(sub_workflow)\n",
        "        .connect_to(\"regroup_input\")\n",
        "        .connect_to(\"append_to_all_user_inputs\")\n",
        "        ## Use different handle to wait different branch\n",
        "        .connect_to(\"wait_point.branch_b\")\n",
        ")"
      ],
      "metadata": {
        "id": "AVSFkd3QL456",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c26ed3a-889d-437d-bd74-dba2429c1ab3"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Agently.Workflow.Chunk.SchemaChunk at 0x77fefee41d80>"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Draw Mermaid Workflow Graph\n",
        "## Yep, I can't use Mermaid() to draw it because it's complex\n",
        "print(workflow.draw())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "foG-awtfMXbf",
        "outputId": "09d11a18-59ec-45d3-d82f-e442176069ab"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "%%{ init: { 'flowchart': { 'curve': 'linear' }, 'theme': 'neutral' } }%%\n",
            "%% Rendered By Agently %%\n",
            "flowchart LR\n",
            "classDef chunk_style fill:#fbfcdb,stroke:#666,stroke-width:1px,color:#333;\n",
            "classDef loop_style fill:#f5f7fa,stroke:#666,stroke-width:1px,color:#333,stroke-dasharray: 5 5\n",
            "    subgraph Loop_1\n",
            "    direction LR\n",
            "    eeefd9bb-48f9-4c67-a65d-db73a5fe5a1b(\"start\"):::chunk_style -.-> |\"* -->-- default\"| e1994333-d244-4853-b8ef-cce16183c074(\"print_char\"):::chunk_style\n",
            "    e1994333-d244-4853-b8ef-cce16183c074(\"print_char\"):::chunk_style -.-> |\"* -->-- default\"| 1298e0ae-080d-43b8-9c17-cb08e6952274(\"end\"):::chunk_style\n",
            "    end\n",
            "    886d5aff-c668-4b51-b5e0-a7985b3850f8(\"start\"):::chunk_style -.-> |\"* -->-- default\"| 72a42165-539d-438c-b07a-02c6dda7be64(\"user_input\"):::chunk_style\n",
            "    72a42165-539d-438c-b07a-02c6dda7be64(\"user_input\"):::chunk_style -.-> |\"* -->-- default\"| 7a03950a-5b10-4667-b5d5-e8af6740bfc6(\"add_times\"):::chunk_style\n",
            "    7a03950a-5b10-4667-b5d5-e8af6740bfc6(\"add_times\"):::chunk_style -.-> |\"* -->-- branch_a\"| 8d9b7d96-18bd-4bd8-9231-52d3ac712c27(\"wait_point\"):::chunk_style\n",
            "    8d9b7d96-18bd-4bd8-9231-52d3ac712c27(\"wait_point\"):::chunk_style -.-> |\"* -- â—‡ -- default\"| 6f20d15d-1b0d-47f8-8795-0336a836638d(\"end\"):::chunk_style\n",
            "    8d9b7d96-18bd-4bd8-9231-52d3ac712c27(\"wait_point\"):::chunk_style -.-> |\"* -- â—‡ -- default\"| 72a42165-539d-438c-b07a-02c6dda7be64(\"user_input\"):::chunk_style\n",
            "    72a42165-539d-438c-b07a-02c6dda7be64(\"user_input\"):::chunk_style -.-> |\"* -->-- default\"| 2a1d5dc2-47b2-4764-9953-b400d39a6d37(\"split_input_to_list\"):::chunk_style\n",
            "    2a1d5dc2-47b2-4764-9953-b400d39a6d37(\"split_input_to_list\"):::chunk_style -.-> |\"* -->-- default\"| Loop_1:::loop_style\n",
            "    Loop_1:::loop_style -.-> |\"* -->-- default\"| d7886aa5-4865-4560-88fc-c8552a2f61ea(\"regroup_input\"):::chunk_style\n",
            "    d7886aa5-4865-4560-88fc-c8552a2f61ea(\"regroup_input\"):::chunk_style -.-> |\"* -->-- default\"| a8958c5a-43b7-448f-8d69-2a9816a3a33c(\"append_to_all_user_inputs\"):::chunk_style\n",
            "    a8958c5a-43b7-448f-8d69-2a9816a3a33c(\"append_to_all_user_inputs\"):::chunk_style -.-> |\"* -->-- branch_b\"| 8d9b7d96-18bd-4bd8-9231-52d3ac712c27(\"wait_point\"):::chunk_style\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<image width=\"1024\" src=\"https://github.com/Maplemx/Agently/assets/4413155/91ddf134-31d5-4afe-9142-6e94e59d022f\" />"
      ],
      "metadata": {
        "id": "8zTF8hDZNhpN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Start Workflow and Get Result\n",
        "workflow.start(storage = { \"times\": 0 })\n",
        "print(workflow.storage.get(\"all_user_inputs\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dSvgF2wROB8L",
        "outputId": "41c0ad26-7215-4151-ec64-c7b024586925"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Input String]: LangGraph\n",
            "L\n",
            "a\n",
            "n\n",
            "g\n",
            "G\n",
            "r\n",
            "a\n",
            "p\n",
            "h\n",
            "LangGraph\n",
            "[Input String]: and\n",
            "a\n",
            "n\n",
            "d\n",
            "and\n",
            "[Input String]: Agently\n",
            "A\n",
            "g\n",
            "e\n",
            "n\n",
            "t\n",
            "l\n",
            "y\n",
            "Agently\n",
            "['LangGraph', 'and', 'Agently']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "[**_<font color = \"red\">Agent</font><font color = \"blue\">ly</font>_** Framework - Speed up your AI application development](https://github.com/Maplemx/Agently)"
      ],
      "metadata": {
        "id": "IT3pSaO2NgkG"
      }
    }
  ]
}